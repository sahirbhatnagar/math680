\documentclass[11pt,letter]{article}    
\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{amssymb} %math symbols
\usepackage{amsmath,amsthm,amssymb,bbm} %math stuff
\usepackage{mathrsfs}
%\usepackage[margin=0.1in]{geometry}
%\usepackage{fullpage}
\usepackage{comment}
\usepackage{ctable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{authblk}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{comment}
\usepackage[round]{natbib}   % omit 'round' option if you prefer square brackets
\bibliographystyle{plainnat}
\usepackage{placeins}
\usepackage{epstopdf}
\usepackage{setspace} %Spacing
\usepackage{graphicx,graphics}
\usepackage{booktabs,tabularx}
\usepackage{enumerate}
\usepackage{makecell}
\usepackage{xfrac}
\usepackage[latin1]{inputenc}
\usepackage{tikz}
\usetikzlibrary{trees}
\usepackage{listings} 
\lstloadlanguages{R} 
\lstset{language=R,basicstyle=\smaller[2],commentstyle=\rmfamily\smaller, 
  showstringspaces=false,% 
  xleftmargin=4ex,literate={<-}{{$\leftarrow$}}1 {~}{{$\sim$}}1} 
\lstset{escapeinside={(*}{*)}}   % for (*\ref{ }*) inside lstlistings (Scode) 
%\usepackage[usenames,dvipsnames]{pstricks}
%\usepackage{epsfig}
%\usepackage{pst-grad} % For gradients
%\usepackage{pst-plot} % For axes

\usepackage{color, colortbl, xcolor}
\definecolor{Gray}{gray}{0.9}

\newcommand {\dsum}{\displaystyle \sum}
\newcommand {\expp}[1]{\exp \left\lbrace {#1}\right\rbrace }
\newcommand {\dprod}{\displaystyle \prod} 
\newcommand {\E}{\mathbb{E}} 
\newcommand {\bs}{\boldsymbol} 
\newcommand{\dpart}[2]{\frac{\partial #1}{\partial #2}}
\newcommand {\tlde}[1] {\underset{\widetilde{}}{#1}}
\newcommand{\inprob}{\xrightarrow p}
\newcommand{\indist}{\xrightarrow d}
\newcommand{\xn}{X_1,\ldots,X_n}
\newcommand{\sumn}{\sum\limits_{i=1}^{n}}
\newcommand{\sumj}{\sum\limits_{j=0}^{\infty}}
\newcommand{\xbar}{\bar{X}}
\newcommand{\odds}[1]{\frac{#1}{1-#1}}
\newcommand{\ww}{\frac{\log t - z\beta}{\sigma}}
\newcommand{\wwm}{\frac{\log t_{0.5} - z\beta}{\sigma}}
\newcommand{\zz}[1]{\left[ {#1}\right] }
\newcommand{\zb}[1]{\left\lbrace  {#1}\right\rbrace  }
\newcommand{\nk}[2]{\left( \begin{array}{c} {#1}\\ {#2} \end{array}\right)}
\newcommand{\nuone}{\frac{\Gamma (\frac{\nu+1}{2})}{\Gamma (\frac{\nu}{2})}}
\newcommand{\nutwo}{\frac{\Gamma (\frac{\nu+2}{2})}{\Gamma (\frac{\nu}{2})}}
\newcommand{\bb}{\boldsymbol{\beta}}
\newcommand{\betaf}{\frac{\Gamma (\alpha+\beta)}{\Gamma (\alpha) \Gamma (\beta)}}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\providecommand{\eeee}[1]{\ensuremath{\times 10^{#1}}}
\setstretch{1} %line spacing

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\pagestyle{empty}

%\pagestyle{plain}
%\newcommand{\hmwkTitle}{Assignment\ \#3} % Assignment title
%\newcommand{\hmwkDueDate}{Monday,\ March\ 24,\ 2014} % Due date
%\newcommand{\hmwkClass}{MATH\ 783} % Course/class
%\newcommand{\hmwkClassTime}{10:05am} % Class/lecture time
%\newcommand{\hmwkClassInstructor}{Dr. Abbas Khalili} % Teacher/lecturer
%\newcommand{\hmwkAuthorName}{Sahir Rai Bhatnagar} % Your name
%\newcommand{\hmwkStudentID}{id \# 260194225} % student id
%\newcommand{\heading}[1]{\bigskip \hrule \smallskip \noindent \texttt{#1} \smallskip \hrule}


\newcommand{\test}[2]{\heading{\textbf{Test }$\bs{H}_0$ : ${#1}$ \textbf{versus} $\bs{H}_A$ : ${#2}$ at $\alpha=0.05$}}
\newcommand{\tm}[1]{\textrm{{#1}}}
\newcommand{\xf}{\mathcal{X}}
\newcommand{\pfrac}[2]{\left( \frac{#1}{#2}\right)}
\newcommand{\e}{{\mathsf E}}
\newcommand{\bt}{\boldsymbol{\theta}}
\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}


\usepackage[pagebackref=true,bookmarks]{hyperref}
                             % Neat package to turn href, ref, cite, gloss entries
                             % into hyperlinks in the dvi file.
                             % Make sure this is the last package loaded.
                             % Use with dvips option to get hyperlinks to work in ps and pdf
                             % files.  Unfortunately, then they don't work in the dvi file!
                             % Use without the dvips option to get the links to work in the dvi file.

                             % Note:  \floatstyle{ruled} don't work properly; so change to plain.
                             % Not as pretty, but functional...
                             % The bookmarks option sets up proper bookmarks in the pdf file :)
\hypersetup{
    unicode=false,          
    pdftoolbar=true,        
    pdfmenubar=true,        
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Assignment 2, MATH 680},    % title
    pdfauthor={Sahir Rai Bhatnagar},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Sahir Rai Bhatnagar},   % creator of the document
    pdfproducer={Sahir Rai Bhatnagar}, % producer of the document
    pdfkeywords={}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=blue,        % color of links to bibliography
    filecolor=black,      % color of file links
    urlcolor=cyan           % color of external links
}

 

%\title{
%\vspace{2in}
%\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
%\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate\ at\ \hmwkClassTime}\\
%\vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
%\vspace{3in}
%}

%\author{\textbf{\hmwkAuthorName}}

%\date{\hmwkStudentID} % Insert date here if you want it to appear below your name
%<<echo=FALSE, results= 'hide', message = FALSE>>=
%options(width=60)
%@
\newcommand{\bh}{\hat{\beta}}
\newcommand{\xtx}{\mathbf{X}^T\mathbf{X}}
\newcommand{\xtxinv}{\left(\mathbf{X}^T\mathbf{X}\right)^{-1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\dnorm}[3]{\frac{1}{\sqrt{2\pi #3}} \expp{- \frac{\left( #1-#2\right) ^2}{2 #3}}  }
\newcommand{\dpois}[3]{\frac{\exp\left(-#2\right) #3 }{#1 !}}

\renewcommand{\headrulewidth}{0.0pt}
\renewcommand{\footrulewidth}{0.0pt}

\setlength{\textheight}{9.00in}
\setlength{\textwidth}{7.00in}
\setlength{\topmargin}{-0.5in}
\setlength{\evensidemargin}{-0.25in}
\setlength{\oddsidemargin}{-0.25in}

\renewcommand{\baselinestretch}{1.2}

\makeatletter

\makeatother
\lfoot{} \cfoot{ } \rfoot{{\small{\em Page \thepage \ of \pageref{LastPage}}}}

\begin{document}
\pagestyle{fancy}

%\title{\vspace{-7ex}MATH 680 - Assignment 1 - February 20, 2015}
%\author{Sahir Bhatnagar \vspace{-4ex}}

\title{MATH 680 - Assignment 2 - March 30, 2015}
\author{Sahir Bhatnagar \& Maxime Turgeon}

\affil{Department of Epidemiology, Biostatistics and Occupational Health \\ McGill University}
%\date{}
\maketitle

%\begin{abstract}
%Here is our abstract.  We have taken the ideas from \citet{WuLange2008}, and coded them up.
%\end{abstract}

\section{Numerical Results}

<<packages,echo=FALSE,warning=FALSE,message=FALSE>>=
setwd("~/git_repositories/math680/")
pkgTest <- function(x)
{
    if (!require(x,character.only = TRUE))
    {
        install.packages(x,dep=TRUE)
        if(!require(x,character.only = TRUE)) stop("Package not found")
    }
}
pkgTest("knitr")
pkgTest("plyr")
pkgTest("data.table")
pkgTest("doParallel")
pkgTest("foreach")
pkgTest("bootstrap")
pkgTest("splines")
pkgTest("ggplot2")
pkgTest("reshape2")
pkgTest("car")
pkgTest("grid")
pkgTest("calibrate")
pkgTest("xtable")
pkgTest("leaps")
registerDoParallel(cores = 4)
source("multiplot.R")
source("functions.R")
@


<<setup, echo=FALSE,warning=FALSE,message=FALSE,cache=FALSE>>=
options(width=70, digits=2)
set.seed(45)
opts_chunk$set(echo = FALSE, tidy = TRUE, cache = FALSE)
opts_template$set(
    fig.large = list(fig.width = 7, fig.height = 5, fig.align = 'center'),
    fig.small = list(fig.width = 3.5, fig.height = 3, fig.align = 'center')
)
knit_hooks$set(crop = hook_pdfcrop)
read_chunk("section1.R")
read_chunk("section2.R")
read_chunk("section3.R")
read_chunk("section4.R")
read_chunk("discussion_sy.R")
#knitr:::knit_code$get()
@

\subsection{Introduction}

<<import-data, echo=FALSE,warning=FALSE,message=FALSE>>=
@

<<hist-compliance,echo=FALSE,fig.cap='Histogram of copmliance values after transformation, so that it looks like a standard normal distribution',fig.align='center',opts.label = 'fig.large', crop = TRUE, eval=FALSE>>=
@

<<figure-1,echo=FALSE,fig.cap='Choleterol decrease vs. compliance with cubic regression fitted curve',fig.align='center',opts.label = 'fig.large', crop = TRUE>>=
@

\subsection{Nonparametric Bootstrap Smoothing}

<<bootstrap-samples>>=
@

<<Cp-boot, cache=TRUE>>=
@

<<Cp-original>>=
@

<<table1, results='asis',echo=FALSE>>=
print(xtable(tab1,digits=0,caption = "$C_p$ model selection for the Cholesterol data. $\\sigma=22$ was used in all bootstrap replications. Last column shows percentage each model was selected as the $C_p$ minimizer, among $B = 4000$ bootstrap replications",align = c("l","l","c","c","c")),include.rownames=FALSE)
@


<<table2, results='asis',echo=FALSE>>=
print(xtable(tab2, caption = "Mean and standard deviation of $\\hat{\\mu}_1^*$ as a function of the selected model, 4000 nonparametric boostrap replications."))
@

<<table21, results='asis',echo=FALSE,warning=FALSE,message=FALSE>>=
print(xtable(tab21, caption = "Mean and standard deviation of $\\hat{\\mu}_1^*$ as a function of the selected model. Some bootstrap samples that led to the quintic and sextic model being selected give a bad fit. Removing them and recomputing table 2 shows that the discrepancy between our table 2 and Efron's is due to bootstrap variability."))
@


<<figure-2,echo=FALSE,fig.cap='Solid points: ratio of standard deviations, taking account of model selection or not, for the 164 values $\\hat{\\mu}_j$ from the regression curve in Figure 1. Dashed line: ratio of $\\tilde{sd}_B$ to $\\hat{sd}_B$',fig.align='center',opts.label = 'fig.large', crop = TRUE>>=
@


<<figure-3,echo=FALSE,fig.cap='B=4000 bootstrap replications of the Cp-OLS regression estimate for Subject 1. Triangles indicate 2.5th and 97.5th percentiles of the histogram',fig.align='center',opts.label = 'fig.large', crop = TRUE>>=
@

<<discussion-1,echo=FALSE,fig.cap='Fitted values for subject 1, from B=4000 nonparametric bootsrap replications separated by three most frequently chosen models by Cp',fig.align='center',opts.label = 'fig.large', crop = TRUE, warning=FALSE, message=FALSE>>=
@



\subsection{Accuracy of the Smoothed Bootstrap Estimates}

<<table-3,echo=FALSE,warning=FALSE, cache=TRUE>>=
@



<<results='asis', echo=FALSE>>=
print(xtable(p.conf,digits = 2, caption = 'Three approximate 95\\% bootstrap confidence intervals 
             for $\\mu_1$, the response for Subject 1, Cholesterol data'),include.rownames=FALSE)
@



\subsection{Parametric Bootstrap Smoothing}

<<figure-5,echo=FALSE,fig.cap='Simulation test of Theorem 2. Cholesterol data; 100 simulations, 1000 parametric bootstraps each, for the 11 subjects indicated at the bottom of Figure 1',fig.align='center',opts.label = 'fig.large', crop = TRUE, cache=TRUE>>=
@


\section{Discussion}

The main example in this paper was based on all subset selection in a linear regression context. The discussion by Wang, Sherwood and Li investigate the proposed method in a regularization procedure, a GLM, quantile and nonparametric regression. Overall, their numerical examples show that Efron's proposed smoothed estimator results in more accurate confidence intervals with good coverage probabilities. The rationale behind using $L_1$-norm type penalty functions for model selection as opposed to the all subset method used by Efron, is due to the well known result that all subset selection methods are unstable~\citep{breiman1996}. Since these model selection procedures are driven by the data, it has been shown that even changing one point from the learning set, can result in a completely different chosen model~\citep{breimanmachine}.

We performed a similar analysis on the \texttt{prostate} data set~\citep{prostate}; a study that examined the relation between level of prostate specific antigen (PSA) and eight clinical measures e.g. Gleason score, cancer volume, prostate weight in 97 men who were about to receive prostatectomy. We produced $B=4000$ bootstrap samples of the \texttt{prostate} data set. For each of the bootstrap samples, we performed model selection using all subset selection as well as LASSO~\citep{Tibshirani94regressionshrinkage}, SCAD~\cite{fanli} and MCP~\cite{zhang2010}. For each model selection procedure, we calculated the fitted value for observation 95 based on the chosen model (resulting in 4000 fitted values for each of the 5 procedures). All the analysis was performed in \texttt{R}~\citep{rcore}. The LASSO was implemented using the \texttt{glmnet} package~\citep{friedmanjstat}. SCAD and MCP were implemented using the coordinate descent algorithm in the \texttt{ncvreg} package~\citep{breheny}. The tuning parameter $\lambda$ was chosen using 5 fold cross validation. Note, for the SCAD and MCP penalties, which have an additional tuning parameter, we used the suggested value of $3.7$ and $3.0$, respectively. All subset selection via the BIC and Cp criterion were implemented using the \texttt{leaps} package~\citep{leaps}. The histograms for the fitted values are given in Figure~\ref{fig:proshist}.   

\begin{figure}[h]
        \centering
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{./mcp_scad_las_hist}
                \caption{$L_1$-Norm Penalty Functions}
                \label{fig:proshist1}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{./bic_cp_hist}
                \caption{All Subset Selection}
                \label{fig:proshist2}
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        %\begin{subfigure}[b]{0.3\textwidth}
        %        \centering
        %        \includegraphics[width=\textwidth]{mouse}
        %        \caption{A mouse}
        %        \label{fig:mouse}
        %\end{subfigure}
        \caption{Histogram of fitted values for subject 95 based on 4000 Bootstrap samples for the \texttt{prostate} data set}\label{fig:proshist}
\end{figure}
\FloatBarrier
Figure~\ref{fig:proshist2} confirms the work of~\cite{breiman1996}, i.e., the all subset selection procedure is very sensitive to changes in the data. The LASSO, SCAD and MCP all produce much more stable estimates, with the distributions of the fitted values looking normal and centred around their mean (Figure~\ref{fig:proshist1}).\\

Figure~\ref{fig:prosconf} compares the lengths of the three confidence intervals types for each procedure. We see that the new smoothed confidence intervals, based on the proposed smoothed standard deviation $\widehat{sd}_B$, outperforms (is shorter) the standard and quantile confidence intervals across all model selection procedures, with the LASSO providing the smallest intervals. Table~\ref{tab:prostab} provides the numerical values of our analysis. Again, we see that the $L_1$-Norm penalties all perform similarly, with good coverage probabilities. Although the coverage probabilities are reasonable for the all subset methods, the length of the interval is much wider. 

\begin{figure}[h]
        \centering
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{./ci_penalty}
                \caption{$L_1$-Norm Penalty Functions}
                \label{fig:prosconf1}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{./ci_penalty_bic}
                \caption{All Subset Selection}
                \label{fig:prosconf2}
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        %\begin{subfigure}[b]{0.3\textwidth}
        %        \centering
        %        \includegraphics[width=\textwidth]{mouse}
        %        \caption{A mouse}
        %        \label{fig:mouse}
        %\end{subfigure}
        \caption{Length of confidence intervals for $\hat{\mu}_{95}$ based on 4000 Bootstrap samples for the \texttt{prostate} data set}\label{fig:prosconf}
\end{figure}



\ctable[caption={Prostate data, B=4000, Observation 95},label=tab:prostab,pos=h!, doinside=\normalsize]{lcccccccc}{}
{
															\FL
model & type & fitted value & sd & length & coverage \ML
LASSO & standard & 3.62 & 0.31 & 1.21 & 0.94 \\ 
   & quantile &  &  & 1.20 & 0.95 \\ 
   & smooth & 3.57 & 0.29 & 1.14 & 0.93 \ML
  SCAD & standard & 3.60 & 0.35 & 1.37 & 0.95 \\ 
   & quantile &  &  & 1.33 & 0.95 \\ 
   & smooth & 3.62 & 0.33 & 1.28 & 0.93 \ML
  MCP & standard & 3.60 & 0.35 & 1.38 & 0.96 \\ 
   & quantile &  &  & 1.35 & 0.95 \\ 
   & smooth & 3.61 & 0.33 & 1.29 & 0.94 \ML
  BIC & standard & 5.50 & 4.75 & 18.62 & 0.84 \\ 
   & quantile &  &  & 16.05 & 0.95 \\ 
   & smooth & 3.22 & 3.46 & 13.55 & 0.83 \ML 
  Cp & standard & 5.13 & 5.11 & 20.02 & 0.86 \\ 
   & quantile &  &  & 16.15 & 0.95 \\ 
   & smooth & 0.64 & 4.40 & 17.24 & 0.97 \LL
}

Wang, Sherwood and Li also show that when the columns of the predictor matrix are orthogonal and $C_p$, AIC or BIC are used as model selection criteria, an analytical solution to the asymptotic variance of the smoothed estimator can be derived . With a numerical example, they show that Efron's estimator performs well in this setting. Professor Politis points out that 
the proposed estimator does not apply to the residual bootstrap because this presupposes a choice of the model. He then gives a summary of his own work on model-free prediction as an alternative approach. Gupta and Lahiri give show two alternative methods for constructing confidence intervals; the Adaptive LASSO~\citep{zou} and maximum frequency Bootstrap-$t$ (MF). The Adaptive LASSO has the oracle property, i.e., it performs as well as if the true underlying model were given in advance and has been shown. The maximum frequency Bootstrap-$t$ limits the calculation of the bagged estimator and its standard error to those resamples that led to the most chosen model. While Gupta and Lahiri's simulations show good performance of this approach, it does not do well in the cholesterol example;  MF 95\% CI [-5.93,15.35] compared to the smoothed interval [-13.3, 8.0]. This is because a substantial number of bootstrap resamples, which led to more negative predicted values are being ignored by the MF.  


\newpage

\FloatBarrier
\bibliography{report}



\end{document}